{
  "cells": [
    {
      "cell_type": "code",
      "id": "NbNEqPOAd3X103xNEgkJB1Zm",
      "metadata": {
        "tags": [],
        "id": "NbNEqPOAd3X103xNEgkJB1Zm"
      },
      "source": [
        "# Install necessary packages (run once)\n",
        "!pip install --upgrade google-cloud-bigquery --quiet\n",
        "!pip install --upgrade google-generativeai --quiet"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.cloud import bigquery\n",
        "import google.generativeai as genai\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "def initialize_services():\n",
        "    \"\"\"Step 1: Initialize BigQuery and Gemini services\"\"\"\n",
        "    project_id = \"qwiklabs-gcp-02-e6e6123d96ed\"\n",
        "\n",
        "    # Initialize BigQuery\n",
        "    try:\n",
        "        bq_client = bigquery.Client(project=project_id)\n",
        "        print(f\"✅ BigQuery connected to project: {project_id}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ BigQuery connection failed: {e}\")\n",
        "        return None, None\n",
        "\n",
        "    # Configure Gemini API\n",
        "    try:\n",
        "        api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
        "        if not api_key:\n",
        "            api_key = input(\"🔐 Enter your Gemini API key: \").strip()\n",
        "\n",
        "        if not api_key:\n",
        "            raise ValueError(\"API key is required\")\n",
        "\n",
        "        genai.configure(api_key=api_key)\n",
        "        model = genai.GenerativeModel(\"gemini-2.5-pro-preview-06-05\")\n",
        "        print(\"✅ Gemini model ready\")\n",
        "\n",
        "        return bq_client, model\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Gemini setup failed: {e}\")\n",
        "        return bq_client, None\n"
      ],
      "metadata": {
        "id": "c3OacUcJIgob"
      },
      "id": "c3OacUcJIgob",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_knowledge_base(bq_client, user_question):\n",
        "    \"\"\"Step 2: Search Aurora Bay knowledge base using vector similarity\"\"\"\n",
        "    search_query = f\"\"\"\n",
        "    SELECT\n",
        "        query.query,\n",
        "        base.content\n",
        "    FROM\n",
        "        VECTOR_SEARCH(\n",
        "            TABLE `my_data_faq.aurora_bay_faq_embedded`,\n",
        "            'ml_generate_embedding_result',\n",
        "            (\n",
        "                SELECT\n",
        "                    ml_generate_embedding_result,\n",
        "                    content AS query\n",
        "                FROM\n",
        "                    ML.GENERATE_EMBEDDING(\n",
        "                        MODEL `my_data_faq.Embeddings`,\n",
        "                        (SELECT '{user_question}' AS content)\n",
        "                    )\n",
        "            ),\n",
        "            top_k => 1,\n",
        "            options => '{{\"fraction_lists_to_search\": 0.01}}'\n",
        "        );\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        query_job = bq_client.query(search_query)\n",
        "        results = query_job.result()\n",
        "\n",
        "        for row in results:\n",
        "            return row.content\n",
        "\n",
        "        return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Search error: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "yBfiTMnWIo6v"
      },
      "id": "yBfiTMnWIo6v",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(model, user_question, context):\n",
        "    \"\"\"Step 3: Generate AI response using retrieved context\"\"\"\n",
        "    system_prompt = f\"\"\"\n",
        "You are an Aurora Bay information assistant. Provide helpful answers using only the information below.\n",
        "If the answer isn't available in the provided content, politely say you don't have that information.\n",
        "\n",
        "Available Information:\n",
        "{context}\n",
        "\n",
        "User Question:\n",
        "{user_question}\n",
        "\n",
        "Response:\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(system_prompt)\n",
        "        return response.text.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Response generation error: {e}\")\n",
        "        return \"Sorry, I encountered an issue generating a response.\"\n",
        "\n"
      ],
      "metadata": {
        "id": "o_7seWG_IuUh"
      },
      "id": "o_7seWG_IuUh",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_chatbot():\n",
        "    \"\"\"Step 4: Main chatbot interaction loop\"\"\"\n",
        "    print(\"\\n--- 🏔️ Aurora Bay Information Assistant ---\")\n",
        "    print(\"💬 Ask me anything about Aurora Bay!\")\n",
        "    print(\"🛑 Type 'quit' or 'exit' to end the conversation.\\n\")\n",
        "\n",
        "    # Initialize services\n",
        "    bq_client, model = initialize_services()\n",
        "\n",
        "    if not bq_client or not model:\n",
        "        print(\"❌ Setup incomplete. Please check your configuration.\")\n",
        "        return\n",
        "\n",
        "    # Main conversation loop\n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(\"👤 You: \").strip()\n",
        "\n",
        "            # Handle exit commands\n",
        "            if user_input.lower() in {\"quit\", \"exit\", \"bye\"}:\n",
        "                print(\"\\n👋 Assistant: Thanks for visiting Aurora Bay! Have a great day! 🌟\")\n",
        "                break\n",
        "\n",
        "            if not user_input:\n",
        "                print(\"⚠️ Please ask a question about Aurora Bay.\")\n",
        "                continue\n",
        "\n",
        "            # Search for relevant information\n",
        "            context = search_knowledge_base(bq_client, user_input)\n",
        "\n",
        "            if not context:\n",
        "                print(\"\\n🤖 Assistant: I couldn't find information about that topic in my Aurora Bay database.\\n\")\n",
        "                continue\n",
        "\n",
        "            # Display retrieved context\n",
        "            display(Markdown(f\"📚 **Found Information:**\\n```\\n{context}\\n```\"))\n",
        "\n",
        "            # Generate and display response\n",
        "            answer = generate_response(model, user_input, context)\n",
        "            display(Markdown(f\"**🤖 Assistant:** {answer}\"))\n",
        "            print()\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\n👋 Assistant: Conversation ended. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n⚠️ Unexpected error: {e}\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_chatbot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "XSa9U9E8JSkI",
        "outputId": "e53e8f9f-69cb-4bf1-da19-d055a26d2ed3"
      },
      "id": "XSa9U9E8JSkI",
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- 🏔️ Aurora Bay Information Assistant ---\n",
            "💬 Ask me anything about Aurora Bay!\n",
            "🛑 Type 'quit' or 'exit' to end the conversation.\n",
            "\n",
            "✅ BigQuery connected to project: qwiklabs-gcp-02-e6e6123d96ed\n",
            "🔐 Enter your Gemini API key: AIzaSyAwzdXAN1XxM3UCHtyWoprvysgPVGSZ0ZU\n",
            "✅ Gemini model ready\n",
            "👤 You: what is the population of aurora bay\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "📚 **Found Information:**\n```\nQuestion: What is the population of Aurora Bay? Answer: Aurora Bay has a population of approximately 3,200 residents, although it can fluctuate seasonally due to temporary fishing and tourism workforces.\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**🤖 Assistant:** Aurora Bay has a population of approximately 3,200 residents, although it can fluctuate seasonally due to temporary fishing and tourism workforces."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "👤 You: exit\n",
            "\n",
            "👋 Assistant: Thanks for visiting Aurora Bay! Have a great day! 🌟\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "student-04-44aebf1ba645 (Jun 16, 2025, 3:15:52 PM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}